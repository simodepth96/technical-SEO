{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simodepth96/technical-SEO/blob/main/JS_vs_TXT_Crawl_Comparison_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compare JS vs TXT-based Crawls from Screaming Frog\n",
        "How much JavaScript impact your target site's raw HTML?  \n",
        "Use this framework to benchmark unwanted discrepancies between two crawls performed with multiple approaches.\n",
        "\n",
        "## Use Cases\n",
        "Comparing two crawls is useful when dealing with **redesigns, migrations, and activity monitoring.**\n",
        "\n",
        "We use this Colab to spot inconsistencies between different versions of the same site (**JS vs Non-JS**, **Mobile vs Desktop**, **Googlebot vs Normal User Agent**), especially during an SEO audit.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##How it works\n",
        "We will load two reports on a Drive folder, then we’ll access these files with Colab to manipulate them and create a new Google Spreadsheet with the difference between them.\n",
        "\n",
        "**⚠️ Please note that if the the Comparison spreadsheet is returned as an empty file, then there are no differences between the JavaScript and the Text-based crawl**\n",
        "\n",
        "##What changes detect\n",
        "Given two crawls we are going to check:\n",
        "\n",
        "- Newly found pages - any URL in the new crawl that isn’t in the old crawl\n",
        "- Newly lost pages - any URL in the old crawl that isn’t in the new crawl\n",
        "- Indexation changes - i.e. Any URL which is now canonicalized or was noindexed\n",
        "- Status code changes - i.e. Any URL which was redirected but is now code 200\n",
        "- URL-level Canonical Tag changes\n",
        "- URL-level Title Tag or Meta Description changes\n",
        "- URL-level H1 or H2 changes\n",
        "\n"
      ],
      "metadata": {
        "id": "FscyJKabw-nD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRywvBFUu-XP"
      },
      "source": [
        "First of all, we need to install `pygsheets` , a Python packet that we'll use to create or edit Spreadsheet in our Google account."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueaN9yEZuVJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87a3d14-e6b5-49ab-9b8e-1b7ddc0d52c8"
      },
      "source": [
        "!pip install --upgrade -q pygsheets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 40 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 61 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 71 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 81 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 92 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 102 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 112 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 122 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 133 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 143 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 147 kB 13.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4wiVSQlvOuW"
      },
      "source": [
        "Colab integrates with Google Docs and Drive ecosystem, giving you a significant boost when analyzing data or testing out new things quickly.\n",
        "\n",
        "Our `internal_all` reports are uploaded on Google Drive, so we'll need to connect to Google Drive.\n",
        "\n",
        " We only need to get our Authorization Code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7ItDxDos3Xa"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2DG_VTMs6IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a431c8d-aef1-4e55-aaac-a6dd4cd5ff62"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlY2PVF6ysgL"
      },
      "source": [
        "In this case our reports are in the folder /diffsf/.\n",
        "![Drive](https://i.gyazo.com/70cce25d55340f1977272d1e7a94825f.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etb1Y4rSs6t-"
      },
      "source": [
        "root_path = '/content/drive/My Drive/Crawls/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1oCJ3uJwQg-"
      },
      "source": [
        "Colab (and Python Notebooks in general) gives you the possibility to use Unix command, adding a ! before the command. You can explore your Drive folder through the Unix command `ls` ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ClHSQ2Is9IS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e689b50e-a16d-4b98-dd6e-95da178fc54a"
      },
      "source": [
        "!ls -lah drive/My\\ Drive/Crawls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 35K\n",
            "-rw------- 1 root root 15K Oct 23 15:16 internal_all.xlsx\n",
            "-rw------- 1 root root 21K Oct 23 15:25 JS_internal_all.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iHBmr21v-_R"
      },
      "source": [
        "Numpy and Pandas are useful packets for data manipulation. They are so powerful and can manage huge files easily. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7bgLMsus5AE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVxrumH2zfxb"
      },
      "source": [
        "Now we need to connect to Spreadsheets. To do this, we need an auth key for accessing Spreadsheet API v4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDBpPMhWuDkN"
      },
      "source": [
        "import google.auth\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "import pygsheets\n",
        "credentials, _ = google.auth.default()\n",
        "gc = pygsheets.client.Client(credentials)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8tOZwg_vozC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec4909b7-9d10-4661-b01e-750430703e5a"
      },
      "source": [
        "sh_name = input(\"Type the filename of your sheets...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type the filename of your sheets...Test SF Crawls Comparison\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR9yUsNEzyS_"
      },
      "source": [
        "Now we'll create a spreadsheet with the name we have given via `sh_name` ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNIT1gdquLez"
      },
      "source": [
        "sh = gc.create(sh_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LJcbXqFDU10"
      },
      "source": [
        "## Open two crawls to compare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw6OedAD2Mu_"
      },
      "source": [
        "Replace `internal_all_21102019.csv` and `internal_all_22102019.csv` with your own files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "580ndo_ytBre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b43853-f1d3-4225-ea96-b56e7d98a65f"
      },
      "source": [
        "internal_all_JS = pd.read_excel(root_path+'JS_internal_all.xlsx',header=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWSELkQztYRV"
      },
      "source": [
        "internal_all_TXT = pd.read_excel(root_path+'internal_all.xlsx',header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QtWqQbGz9mX"
      },
      "source": [
        "Here we'll filter out all non-html requests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i-I-vCWtfA0"
      },
      "source": [
        "JS_crawl = internal_all_JS[internal_all_JS['Content Type'].str.contains(\"text/html\", na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfR_lOfqtlWC"
      },
      "source": [
        "TXT_crawl = internal_all_TXT[internal_all_TXT['Content Type'].str.contains(\"text/html\", na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCAwy13o035A"
      },
      "source": [
        "[Pandas info method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) is useful when we need to know quickly what reports contains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ51C9ET1HOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947363e9-2580-4129-928b-e94fafe6e59a"
      },
      "source": [
        "JS_crawl.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 32 entries, 0 to 61\n",
            "Data columns (total 57 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   Address                         32 non-null     object \n",
            " 1   Content Type                    32 non-null     object \n",
            " 2   Status Code                     32 non-null     float64\n",
            " 3   Status                          9 non-null      object \n",
            " 4   Indexability                    32 non-null     object \n",
            " 5   Indexability Status             9 non-null      object \n",
            " 6   Title 1                         23 non-null     object \n",
            " 7   Title 1 Length                  32 non-null     float64\n",
            " 8   Title 1 Pixel Width             32 non-null     float64\n",
            " 9   Meta Description 1              23 non-null     object \n",
            " 10  Meta Description 1 Length       32 non-null     float64\n",
            " 11  Meta Description 1 Pixel Width  32 non-null     float64\n",
            " 12  Meta Keywords 1                 0 non-null      float64\n",
            " 13  Meta Keywords 1 Length          0 non-null      float64\n",
            " 14  H1-1                            23 non-null     object \n",
            " 15  H1-1 Length                     32 non-null     float64\n",
            " 16  H1-2                            4 non-null      object \n",
            " 17  H1-2 Length                     32 non-null     float64\n",
            " 18  H2-1                            0 non-null      float64\n",
            " 19  H2-1 Length                     0 non-null      float64\n",
            " 20  Meta Robots 1                   23 non-null     object \n",
            " 21  X-Robots-Tag 1                  0 non-null      float64\n",
            " 22  Meta Refresh 1                  0 non-null      float64\n",
            " 23  Canonical Link Element 1        23 non-null     object \n",
            " 24  rel=\"next\" 1                    1 non-null      object \n",
            " 25  rel=\"prev\" 1                    1 non-null      object \n",
            " 26  HTTP rel=\"next\" 1               0 non-null      float64\n",
            " 27  HTTP rel=\"prev\" 1               0 non-null      float64\n",
            " 28  amphtml Link Element            0 non-null      float64\n",
            " 29  Size (bytes)                    0 non-null      float64\n",
            " 30  Word Count                      0 non-null      float64\n",
            " 31  Text Ratio                      0 non-null      float64\n",
            " 32  Crawl Depth                     32 non-null     float64\n",
            " 33  Link Score                      0 non-null      float64\n",
            " 34  Inlinks                         32 non-null     float64\n",
            " 35  Unique Inlinks                  32 non-null     float64\n",
            " 36  Unique JS Inlinks               32 non-null     float64\n",
            " 37  % of Total                      32 non-null     float64\n",
            " 38  Outlinks                        32 non-null     float64\n",
            " 39  Unique Outlinks                 32 non-null     float64\n",
            " 40  Unique JS Outlinks              32 non-null     float64\n",
            " 41  External Outlinks               32 non-null     float64\n",
            " 42  Unique External Outlinks        32 non-null     float64\n",
            " 43  Unique External JS Outlinks     32 non-null     float64\n",
            " 44  Closest Similarity Match        0 non-null      float64\n",
            " 45  No. Near Duplicates             0 non-null      float64\n",
            " 46  Spelling Errors                 0 non-null      float64\n",
            " 47  Grammar Errors                  0 non-null      float64\n",
            " 48  Hash                            0 non-null      float64\n",
            " 49  Response Time                   32 non-null     float64\n",
            " 50  Last Modified                   21 non-null     object \n",
            " 51  Redirect URL                    9 non-null      object \n",
            " 52  Redirect Type                   9 non-null      object \n",
            " 53  Cookies                         0 non-null      float64\n",
            " 54  HTTP Version                    23 non-null     object \n",
            " 55  URL Encoded Address             32 non-null     object \n",
            " 56  Crawl Timestamp                 32 non-null     object \n",
            "dtypes: float64(38), object(19)\n",
            "memory usage: 14.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XRlwLWO1Isd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bdedddb-726c-4558-c2e5-d0fbf50d8d82"
      },
      "source": [
        "TXT_crawl.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 32 entries, 0 to 32\n",
            "Data columns (total 57 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   Address                         32 non-null     object \n",
            " 1   Content Type                    32 non-null     object \n",
            " 2   Status Code                     32 non-null     float64\n",
            " 3   Status                          32 non-null     object \n",
            " 4   Indexability                    32 non-null     object \n",
            " 5   Indexability Status             9 non-null      object \n",
            " 6   Title 1                         23 non-null     object \n",
            " 7   Title 1 Length                  32 non-null     float64\n",
            " 8   Title 1 Pixel Width             32 non-null     float64\n",
            " 9   Meta Description 1              23 non-null     object \n",
            " 10  Meta Description 1 Length       32 non-null     float64\n",
            " 11  Meta Description 1 Pixel Width  32 non-null     float64\n",
            " 12  Meta Keywords 1                 0 non-null      float64\n",
            " 13  Meta Keywords 1 Length          0 non-null      float64\n",
            " 14  H1-1                            23 non-null     object \n",
            " 15  H1-1 Length                     32 non-null     float64\n",
            " 16  H1-2                            4 non-null      object \n",
            " 17  H1-2 Length                     32 non-null     float64\n",
            " 18  H2-1                            0 non-null      float64\n",
            " 19  H2-1 Length                     0 non-null      float64\n",
            " 20  Meta Robots 1                   23 non-null     object \n",
            " 21  X-Robots-Tag 1                  0 non-null      float64\n",
            " 22  Meta Refresh 1                  0 non-null      float64\n",
            " 23  Canonical Link Element 1        23 non-null     object \n",
            " 24  rel=\"next\" 1                    1 non-null      object \n",
            " 25  rel=\"prev\" 1                    1 non-null      object \n",
            " 26  HTTP rel=\"next\" 1               0 non-null      float64\n",
            " 27  HTTP rel=\"prev\" 1               0 non-null      float64\n",
            " 28  amphtml Link Element            0 non-null      float64\n",
            " 29  Size (bytes)                    0 non-null      float64\n",
            " 30  Word Count                      0 non-null      float64\n",
            " 31  Text Ratio                      0 non-null      float64\n",
            " 32  Crawl Depth                     32 non-null     float64\n",
            " 33  Link Score                      0 non-null      float64\n",
            " 34  Inlinks                         32 non-null     float64\n",
            " 35  Unique Inlinks                  32 non-null     float64\n",
            " 36  Unique JS Inlinks               32 non-null     float64\n",
            " 37  % of Total                      32 non-null     float64\n",
            " 38  Outlinks                        32 non-null     float64\n",
            " 39  Unique Outlinks                 32 non-null     float64\n",
            " 40  Unique JS Outlinks              32 non-null     float64\n",
            " 41  External Outlinks               32 non-null     float64\n",
            " 42  Unique External Outlinks        32 non-null     float64\n",
            " 43  Unique External JS Outlinks     32 non-null     float64\n",
            " 44  Closest Similarity Match        0 non-null      float64\n",
            " 45  No. Near Duplicates             0 non-null      float64\n",
            " 46  Spelling Errors                 0 non-null      float64\n",
            " 47  Grammar Errors                  0 non-null      float64\n",
            " 48  Hash                            0 non-null      float64\n",
            " 49  Response Time                   32 non-null     float64\n",
            " 50  Last Modified                   11 non-null     object \n",
            " 51  Redirect URL                    9 non-null      object \n",
            " 52  Redirect Type                   9 non-null      object \n",
            " 53  Cookies                         0 non-null      float64\n",
            " 54  HTTP Version                    32 non-null     object \n",
            " 55  URL Encoded Address             32 non-null     object \n",
            " 56  Crawl Timestamp                 32 non-null     object \n",
            "dtypes: float64(38), object(19)\n",
            "memory usage: 14.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZEfGFLfDOTz"
      },
      "source": [
        "## New found Pages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KGq7r_20Mho"
      },
      "source": [
        "Through `pd.merge` we are going to merge the JavaScript and the Text-based crawl using the URLs as their common key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsMV724ItzQ8"
      },
      "source": [
        "_new_found_pages = pd.merge(JS_crawl,\\\n",
        "                            TXT_crawl,\\\n",
        "                            suffixes=('_JS_crawl', '_TXT_crawl'),\\\n",
        "                            on='Address',\\\n",
        "                            how='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umV1Virb0iV7"
      },
      "source": [
        "We'll filter out all null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5aQ5cjlt0yM"
      },
      "source": [
        "_new_found_pages = _new_found_pages[_new_found_pages['Status Code_JS_crawl'].isna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fDOjGz50m_B"
      },
      "source": [
        "And keep only the columns that contains `_current` (from the latest crawl) and `Address`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Saqxnzqlt4l2"
      },
      "source": [
        "new_found_pages = _new_found_pages.filter(regex='Address|\\_TXT_crawl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqPlrfC9t9Lf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df2a1c2-b75e-4ff4-d306-7fba00638a94"
      },
      "source": [
        "new_found_pages.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 0 entries\n",
            "Data columns (total 58 columns):\n",
            " #   Column                                    Non-Null Count  Dtype  \n",
            "---  ------                                    --------------  -----  \n",
            " 0   Address                                   0 non-null      object \n",
            " 1   URL Encoded Address_JS_crawl              0 non-null      object \n",
            " 2   Content Type_TXT_crawl                    0 non-null      object \n",
            " 3   Status Code_TXT_crawl                     0 non-null      float64\n",
            " 4   Status_TXT_crawl                          0 non-null      object \n",
            " 5   Indexability_TXT_crawl                    0 non-null      object \n",
            " 6   Indexability Status_TXT_crawl             0 non-null      object \n",
            " 7   Title 1_TXT_crawl                         0 non-null      object \n",
            " 8   Title 1 Length_TXT_crawl                  0 non-null      float64\n",
            " 9   Title 1 Pixel Width_TXT_crawl             0 non-null      float64\n",
            " 10  Meta Description 1_TXT_crawl              0 non-null      object \n",
            " 11  Meta Description 1 Length_TXT_crawl       0 non-null      float64\n",
            " 12  Meta Description 1 Pixel Width_TXT_crawl  0 non-null      float64\n",
            " 13  Meta Keywords 1_TXT_crawl                 0 non-null      float64\n",
            " 14  Meta Keywords 1 Length_TXT_crawl          0 non-null      float64\n",
            " 15  H1-1_TXT_crawl                            0 non-null      object \n",
            " 16  H1-1 Length_TXT_crawl                     0 non-null      float64\n",
            " 17  H1-2_TXT_crawl                            0 non-null      object \n",
            " 18  H1-2 Length_TXT_crawl                     0 non-null      float64\n",
            " 19  H2-1_TXT_crawl                            0 non-null      float64\n",
            " 20  H2-1 Length_TXT_crawl                     0 non-null      float64\n",
            " 21  Meta Robots 1_TXT_crawl                   0 non-null      object \n",
            " 22  X-Robots-Tag 1_TXT_crawl                  0 non-null      float64\n",
            " 23  Meta Refresh 1_TXT_crawl                  0 non-null      float64\n",
            " 24  Canonical Link Element 1_TXT_crawl        0 non-null      object \n",
            " 25  rel=\"next\" 1_TXT_crawl                    0 non-null      object \n",
            " 26  rel=\"prev\" 1_TXT_crawl                    0 non-null      object \n",
            " 27  HTTP rel=\"next\" 1_TXT_crawl               0 non-null      float64\n",
            " 28  HTTP rel=\"prev\" 1_TXT_crawl               0 non-null      float64\n",
            " 29  amphtml Link Element_TXT_crawl            0 non-null      float64\n",
            " 30  Size (bytes)_TXT_crawl                    0 non-null      float64\n",
            " 31  Word Count_TXT_crawl                      0 non-null      float64\n",
            " 32  Text Ratio_TXT_crawl                      0 non-null      float64\n",
            " 33  Crawl Depth_TXT_crawl                     0 non-null      float64\n",
            " 34  Link Score_TXT_crawl                      0 non-null      float64\n",
            " 35  Inlinks_TXT_crawl                         0 non-null      float64\n",
            " 36  Unique Inlinks_TXT_crawl                  0 non-null      float64\n",
            " 37  Unique JS Inlinks_TXT_crawl               0 non-null      float64\n",
            " 38  % of Total_TXT_crawl                      0 non-null      float64\n",
            " 39  Outlinks_TXT_crawl                        0 non-null      float64\n",
            " 40  Unique Outlinks_TXT_crawl                 0 non-null      float64\n",
            " 41  Unique JS Outlinks_TXT_crawl              0 non-null      float64\n",
            " 42  External Outlinks_TXT_crawl               0 non-null      float64\n",
            " 43  Unique External Outlinks_TXT_crawl        0 non-null      float64\n",
            " 44  Unique External JS Outlinks_TXT_crawl     0 non-null      float64\n",
            " 45  Closest Similarity Match_TXT_crawl        0 non-null      float64\n",
            " 46  No. Near Duplicates_TXT_crawl             0 non-null      float64\n",
            " 47  Spelling Errors_TXT_crawl                 0 non-null      float64\n",
            " 48  Grammar Errors_TXT_crawl                  0 non-null      float64\n",
            " 49  Hash_TXT_crawl                            0 non-null      float64\n",
            " 50  Response Time_TXT_crawl                   0 non-null      float64\n",
            " 51  Last Modified_TXT_crawl                   0 non-null      object \n",
            " 52  Redirect URL_TXT_crawl                    0 non-null      object \n",
            " 53  Redirect Type_TXT_crawl                   0 non-null      object \n",
            " 54  Cookies_TXT_crawl                         0 non-null      float64\n",
            " 55  HTTP Version_TXT_crawl                    0 non-null      object \n",
            " 56  URL Encoded Address_TXT_crawl             0 non-null      object \n",
            " 57  Crawl Timestamp_TXT_crawl                 0 non-null      object \n",
            "dtypes: float64(38), object(20)\n",
            "memory usage: 0.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI_ZgEUXFbXh"
      },
      "source": [
        "Now we're going to evaluate if the `new_found_pages` DataFrame is empty. If not, we are going to create a new worksheet and append the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzAB0eJmFHrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88cb826-45f0-441a-f408-0315669cf0cf"
      },
      "source": [
        "if len(new_found_pages['Address'].tolist()) == 0:\n",
        "  print('No changes detected!')\n",
        "else:\n",
        "  #Now we need to select the first Sheet in our Spreadsheet. \n",
        "  #To access it, we need to select it through an index (0-based).\n",
        "  wks = sh[0]\n",
        "  #set_dataframe is a method that injects a DataFrame into a spreadsheet. \n",
        "  #The first argument is the DF and the second arg is the cell where we start filling.\n",
        "  wks.set_dataframe(new_found_pages, 'A1',fit=True)\n",
        "  #We can also change the title of our worksheet, in this way\n",
        "  sh.sheet1.title=\"New Found Pages\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No changes detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i83p2c8NBjdA"
      },
      "source": [
        "## Newly lost pages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjKIe2SlB4IV"
      },
      "source": [
        "_new_lost_pages = _new_found_pages[_new_found_pages['Status Code_TXT_crawl'].isna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbXBySPyLAl_"
      },
      "source": [
        "new_lost_pages = _new_found_pages.filter(regex='Address|\\_JS_crawl').dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngKu-aInFtGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8390e0d-3c2d-43d5-bb05-f039c65badb1"
      },
      "source": [
        "if len(new_lost_pages['Address'].tolist()) == 0:\n",
        "  print('No changes detected!')\n",
        "else:\n",
        "  #Now let's add a new worksheet with a title\n",
        "  wks = sh.add_worksheet('New Lost Pages')\n",
        "  #Append a DataFrame in our new worksheet\n",
        "  wks.set_dataframe(new_lost_pages, 'A1',fit=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No changes detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFS9Tr_6CRPD"
      },
      "source": [
        "## Changed Status Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2dpHyJ7CUwC"
      },
      "source": [
        "_changed_status_code = pd.merge(previous[['Address','Status Code']],\\\n",
        "                                current[['Address','Status Code']],\\\n",
        "                                suffixes=('_prev', '_current'),\\\n",
        "                                on='Address',\\\n",
        "                                how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF69HnsNCWM3"
      },
      "source": [
        "_changed_status_code['diff'] = np.where(_changed_status_code['Status Code_prev'] == _changed_status_code['Status Code_current'], 'no change', 'changed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7ArLcomCZVR"
      },
      "source": [
        "changed_status_code = _changed_status_code[_changed_status_code['diff'] == 'changed']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3b-_kWfGAHe"
      },
      "source": [
        "if len(changed_status_code['Address'].tolist()) == 0:\n",
        "  print('No changes detected!')\n",
        "else:\n",
        "  #Now let's add a new worksheet with a title\n",
        "  wks = sh.add_worksheet('Changed Status Code')\n",
        "  #Append a DataFrame in our new worksheet\n",
        "  wks.set_dataframe(changed_status_code, 'A1',fit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWZ-TYJ-CiFb"
      },
      "source": [
        "## changed indexation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikNX2ocrCht8"
      },
      "source": [
        "_changed_indexation = pd.merge(JS_crawl[['Address','Status Code', 'Indexability','Indexability Status']],\\\n",
        "                                TXT_crawl[['Address','Status Code', 'Indexability','Indexability Status']],\\\n",
        "                                suffixes=('_JS_crawl', '_TXT_crawl'), on='Address', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b_-05ZLCk4n"
      },
      "source": [
        "_changed_indexation['diff'] = np.where(_changed_indexation['Indexability_JS_crawl'] == _changed_indexation['Indexability_TXT_crawl'], 'no change', 'changed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjkLgTbBCm5s"
      },
      "source": [
        "changed_indexation = _changed_indexation[['Address','Indexability_JS_crawl','Indexability Status_JS_crawl','Indexability_TXT_crawl','Indexability Status_TXT_crawl','diff']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj7i3IOeCqLb"
      },
      "source": [
        "changed_indexation = changed_indexation[changed_indexation['diff'] == 'changed']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-LN6s5EGIFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcff6de-2f23-44ac-e9de-dfcc1ac38480"
      },
      "source": [
        "if len(changed_indexation['Address'].tolist()) == 0:\n",
        "  print('No changes detected!')\n",
        "else:\n",
        "  #Now let's add a new worksheet with a title\n",
        "  wks = sh.add_worksheet('Changed Indexation')\n",
        "  #Append a DataFrame in our new worksheet\n",
        "  wks.set_dataframe(changed_indexation, 'A1',fit=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No changes detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsezHZIcCt_p"
      },
      "source": [
        "## changed meta\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVc-jclACyk2"
      },
      "source": [
        "_changed_meta = pd.merge(JS_crawl[['Address','Title 1', 'Meta Description 1']],\\\n",
        "                                TXT_crawl[['Address','Title 1', 'Meta Description 1']],\\\n",
        "                                suffixes=('_JS_crawl', '_TXT_crawl'), on='Address', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21XPnB4_C5lH"
      },
      "source": [
        "_changed_meta['diff_title'] = np.where(_changed_meta['Title 1_JS_crawl'] == _changed_meta['Title 1_TXT_crawl'], 'no change', 'changed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIxw55gBC98s"
      },
      "source": [
        "_changed_meta['diff_desc'] = np.where(_changed_meta['Meta Description 1_JS_crawl'] == _changed_meta['Meta Description 1_TXT_crawl'], 'no change', 'changed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGOBOrknDCMk"
      },
      "source": [
        "changed_title = _changed_meta[_changed_meta['diff_title'] == 'changed'].dropna().filter(regex='Address|^Title.+|diff\\_title')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r21aZqohDHBA"
      },
      "source": [
        "changed_desc= _changed_meta[_changed_meta['diff_desc'] == 'changed'].dropna().filter(regex='Address|.+Description.+|diff\\_desc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiiwY5fsGN9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0959e7-8c35-4002-c7c1-aa36f9f3f5ad"
      },
      "source": [
        "if len(changed_title['Address'].tolist()) == 0:\n",
        "  print('No changes detected!')\n",
        "else:\n",
        "  #Now let's add a new worksheet with a title\n",
        "  wks = sh.add_worksheet('Changed Title')\n",
        "  #Append a DataFrame in our new worksheet\n",
        "  wks.set_dataframe(changed_title, 'A1',fit=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No changes detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHdnoxj9HHQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b571075c-e704-46ea-f212-b61593412c65"
      },
      "source": [
        "if len(changed_desc['Address'].tolist()) == 0:\n",
        "  print('No changes detected!')\n",
        "else:\n",
        "  #Now let's add a new worksheet with a title\n",
        "  wks = sh.add_worksheet('Changed Description')\n",
        "  #Append a DataFrame in our new worksheet\n",
        "  wks.set_dataframe(changed_desc, 'A1',fit=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No changes detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lZnpIwzDJHS"
      },
      "source": [
        "## changed H1 tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQPIbo8PDcxO"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWUWFws-DXat"
      },
      "source": [
        "changed_h1 = pd.merge(JS_crawl.filter(regex='Address|^H1\\-\\d{1,2}$').dropna(thresh=3),\\\n",
        "                            TXT_crawl.filter(regex='Address|^H1\\-\\d{1,2}$').dropna(thresh=3),\\\n",
        "                            suffixes=('_JS_crawl', '_TXT_crawl'),\\\n",
        "                            on='Address',\\\n",
        "                            how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaD3yEqHDZUO"
      },
      "source": [
        "changed_h1.replace(np.nan, '', regex=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tFieyPuDkTb"
      },
      "source": [
        "changed_h1_cols = TXT_crawl.filter(regex='Address|^H1\\-\\d{1,2}$').dropna(thresh=3).columns.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vWYn3RKDamy"
      },
      "source": [
        "r = re.compile(\"^H1\\-\\d{1,2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTHj1UiPDfbK"
      },
      "source": [
        "newlist = list(filter(r.match, changed_h1_cols))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drlYqQBsDm1Y"
      },
      "source": [
        "for i in range(1,len(newlist)+1):\n",
        "    new_diff = \"H1-\"+str(i)\n",
        "    new = f\"{new_diff}_TXT_crawl\"\n",
        "    old = f\"{new_diff}_JS_crawl\"\n",
        "    _tmp = f\"diff-{new_diff}\"\n",
        "    changed_h1[_tmp] = changed_h1[new] != changed_h1[old]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R-tv-U2Do1B"
      },
      "source": [
        "changed_h1.columns =[column.replace(\"-\", \"_\") for column in changed_h1.columns] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nn6epaeDqKF"
      },
      "source": [
        "diff_col_lst = changed_h1.filter(regex='diff\\_H1').columns.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZukFnhiyDrkp"
      },
      "source": [
        "exp = ' or '.join(diff_col_lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNjvc8gjDsIE"
      },
      "source": [
        "changed_h1 = changed_h1.query(exp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsIOeKHgHRQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6771a386-0317-445a-b809-7775a89f5806"
      },
      "source": [
        "if len(changed_h1['Address'].tolist()) == 0:\n",
        "  print('No changes detected!')\n",
        "else:\n",
        "  #Now let's add a new worksheet with a title\n",
        "  wks = sh.add_worksheet('Changed H1')\n",
        "  #Append a DataFrame in our new worksheet\n",
        "  wks.set_dataframe(changed_h1, 'A1',fit=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No changes detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTjEe-2WDutP"
      },
      "source": [
        "## Changed H2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IyLthXZD0UI"
      },
      "source": [
        "changed_h2 = pd.merge(JS_crawl.filter(regex='Address|^H2\\-\\d{1,2}$').dropna(thresh=3),\\\n",
        "                TXT_crawl.filter(regex='Address|^H2\\-\\d{1,2}$').dropna(thresh=3),\\\n",
        "                suffixes=('_JS_crawl', '_TXT_crawl'),\\\n",
        "                on='Address',\\\n",
        "                how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOAdK1nbD4Xr"
      },
      "source": [
        "changed_h2.replace(np.nan, '', regex=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8WvhqKCD6o3"
      },
      "source": [
        "changed_h2_cols = TXT_crawl.filter(regex='Address|^H2\\-\\d{1,2}$').dropna(thresh=3).columns.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxbnmaKFD7y9"
      },
      "source": [
        "r = re.compile(\"^H2\\-\\d{1,2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvlbkuRKD9Zu"
      },
      "source": [
        "newlist = list(filter(r.match, changed_h2_cols))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IOdFsW8D-DV"
      },
      "source": [
        "for i in range(1,len(newlist)+1):\n",
        "    new_diff = \"H2-\"+str(i)\n",
        "    new = f\"{new_diff}_TXT_crawl\"\n",
        "    old = f\"{new_diff}_JS_crawl\"\n",
        "    _tmp = f\"diff-{new_diff}\"\n",
        "    changed_h2[_tmp] = changed_h2[new] != changed_h2[old]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2m_JmZ7EA1H"
      },
      "source": [
        "changed_h2.columns =[column.replace(\"-\", \"_\") for column in changed_h2.columns] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7WQFyoWECG9"
      },
      "source": [
        "diff_col_lst = changed_h2.filter(regex='diff\\_H2').columns.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPLFvnRmEDU2"
      },
      "source": [
        "exp = ' or '.join(diff_col_lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQTG5TEwEEyg"
      },
      "source": [
        "changed_h2 = changed_h2.query(exp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv-tKVlsHWK7"
      },
      "source": [
        "if len(changed_h2['Address'].tolist()) == 0:\n",
        "  print('No changes detected!')\n",
        "else:\n",
        "  #Now let's add a new worksheet with a title\n",
        "  wks = sh.add_worksheet('Changed H2')\n",
        "  #Append a DataFrame in our new worksheet\n",
        "  wks.set_dataframe(changed_h2, 'A1',fit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30Ccen5xDiZm"
      },
      "source": [
        "## Changed canonicals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXXq3t_DDkHG"
      },
      "source": [
        "_changed_canonical = pd.merge(JS_crawl[['Address','Status Code','Canonical Link Element 1']],TXT_crawl[['Address','Status Code','Canonical Link Element 1']],\\\n",
        "                               suffixes=('_JS_crawl', '_TXT_crawl'), on='Address', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPzzMWiAEp1E"
      },
      "source": [
        "_changed_canonical.replace(np.nan, '', regex=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKQhLbBJEQ43"
      },
      "source": [
        "_changed_canonical['diff_canonical'] = np.where(_changed_canonical['Canonical Link Element 1_JS_crawl'] == _changed_canonical['Canonical Link Element 1_TXT_crawl'], 'no change', 'changed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HtOFjYvEYJ0"
      },
      "source": [
        "changed_canonical = _changed_canonical[_changed_canonical['diff_canonical'] == 'changed']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmEtrEY4Hbnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3a2c65-a9ef-4b0d-9a62-99a33ddc0ada"
      },
      "source": [
        "if len(changed_canonical['Address'].tolist()) == 0:\n",
        "  print('No changes detected!')\n",
        "else:\n",
        "  #Now let's add a new worksheet with a title\n",
        "  wks = sh.add_worksheet('Changed Canonicals')\n",
        "  #Append a DataFrame in our new worksheet\n",
        "  wks.set_dataframe(changed_canonical, 'A1',fit=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No changes detected!\n"
          ]
        }
      ]
    }
  ]
}